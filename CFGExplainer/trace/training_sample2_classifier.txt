2023-06-09 14:40:23.217736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-06-09 14:40:23.981882: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-06-09 14:40:23.982430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-06-09 14:40:24.024818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-09 14:40:24.024954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3080 Ti computeCapability: 8.6
coreClock: 1.83GHz coreCount: 80 deviceMemorySize: 11.75GiB deviceMemoryBandwidth: 849.46GiB/s
2023-06-09 14:40:24.024968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-06-09 14:40:24.026669: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-06-09 14:40:24.026755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-06-09 14:40:24.027564: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-06-09 14:40:24.027767: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-06-09 14:40:24.029753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-06-09 14:40:24.030221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-06-09 14:40:24.030357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-06-09 14:40:24.030422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-09 14:40:24.030546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-09 14:40:24.030625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-06-09 14:46:20.733450: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-06-09 14:46:20.733720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-09 14:46:20.733845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3080 Ti computeCapability: 8.6
coreClock: 1.83GHz coreCount: 80 deviceMemorySize: 11.75GiB deviceMemoryBandwidth: 849.46GiB/s
2023-06-09 14:46:20.733871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-06-09 14:46:20.733893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-06-09 14:46:20.733899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-06-09 14:46:20.733906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-06-09 14:46:20.733912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-06-09 14:46:20.733918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-06-09 14:46:20.733935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-06-09 14:46:20.733940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-06-09 14:46:20.733968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-09 14:46:20.734036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-09 14:46:20.734109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-06-09 14:46:20.734122: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-06-09 14:46:21.024534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-06-09 14:46:21.024572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2023-06-09 14:46:21.024578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2023-06-09 14:46:21.024729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-09 14:46:21.024878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-09 14:46:21.024952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-09 14:46:21.025054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10873 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6)
2023-06-09 14:46:21.026348: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 8388608000 exceeds 10% of free system memory.
2023-06-09 14:48:02.435815: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2097152000 exceeds 10% of free system memory.
2023-06-09 14:48:08.272275: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 8388608000 exceeds 10% of free system memory.
2023-06-09 14:48:13.021933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-06-09 14:48:13.372673: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-06-09 14:48:13.386351: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-09 14:48:43.772916: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2097152000 exceeds 10% of free system memory.
2023-06-09 14:48:49.167604: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 8388608000 exceeds 10% of free system memory.
sys.args:  ['exp_train_GCNClassifier.py', '10', 'data_poison', '1024-512-128', '0.0001', 'GCNClassifier', '5%_poison_connlabcfg', '200']
+ loaded padded_train Benign
+ loaded padded_train Malware
+ loaded train dataset
+ loaded padded_test Benign
+ loaded padded_test Malware
+ loaded test dataset
created Graph GCN model
+ model: 
 <util.models.GCN object at 0x7fed86d6e970>
ep:  0 train loss:  0.3773830 train acc:  0.8496250
ep:  1 train loss:  0.2251298 train acc:  0.9211250
ep:  2 train loss:  0.2116953 train acc:  0.9321250
ep:  3 train loss:  0.1908755 train acc:  0.9363750
ep:  4 train loss:  0.1828737 train acc:  0.9396250
ep:  5 train loss:  0.1611238 train acc:  0.9425000
ep:  6 train loss:  0.1227550 train acc:  0.9621250
ep:  7 train loss:  0.1093910 train acc:  0.9657500
ep:  8 train loss:  0.1054936 train acc:  0.9666250
ep:  9 train loss:  0.1027702 train acc:  0.9673750
ep:  10 train loss:  0.0947192 train acc:  0.9703750
ep:  11 train loss:  0.0912252 train acc:  0.9700000
ep:  12 train loss:  0.0886246 train acc:  0.9716250
ep:  13 train loss:  0.0858514 train acc:  0.9742500
ep:  14 train loss:  0.0852025 train acc:  0.9751250
ep:  15 train loss:  0.0845063 train acc:  0.9755000
ep:  16 train loss:  0.0849415 train acc:  0.9768750
ep:  17 train loss:  0.0777593 train acc:  0.9778750
ep:  18 train loss:  0.0782888 train acc:  0.9773750
ep:  19 train loss:  0.0766894 train acc:  0.9776250
ep:  20 train loss:  0.0768243 train acc:  0.9777500
ep:  21 train loss:  0.0764789 train acc:  0.9776250
ep:  22 train loss:  0.0801316 train acc:  0.9792500
ep:  23 train loss:  0.0728035 train acc:  0.9797500
ep:  24 train loss:  0.0711749 train acc:  0.9807500
ep:  25 train loss:  0.0702858 train acc:  0.9795000
ep:  26 train loss:  0.0729923 train acc:  0.9795000
ep:  27 train loss:  0.0709242 train acc:  0.9806250
ep:  28 train loss:  0.0677130 train acc:  0.9820000
ep:  29 train loss:  0.0704598 train acc:  0.9803750
ep:  30 train loss:  0.0680760 train acc:  0.9820000
ep:  31 train loss:  0.0675589 train acc:  0.9816250
ep:  32 train loss:  0.0655064 train acc:  0.9832500
ep:  33 train loss:  0.0683048 train acc:  0.9815000
ep:  34 train loss:  0.0662685 train acc:  0.9816250
ep:  35 train loss:  0.0653519 train acc:  0.9828750
ep:  36 train loss:  0.0650078 train acc:  0.9830000
ep:  37 train loss:  0.0640376 train acc:  0.9832500
ep:  38 train loss:  0.0665245 train acc:  0.9827500
ep:  39 train loss:  0.0624647 train acc:  0.9838750
ep:  40 train loss:  0.0628143 train acc:  0.9838750
ep:  41 train loss:  0.0614863 train acc:  0.9841250
ep:  42 train loss:  0.0618408 train acc:  0.9840000
ep:  43 train loss:  0.0615675 train acc:  0.9848750
ep:  44 train loss:  0.0621724 train acc:  0.9841250
ep:  45 train loss:  0.0618947 train acc:  0.9855000
ep:  46 train loss:  0.0609569 train acc:  0.9848750
ep:  47 train loss:  0.0586031 train acc:  0.9847500
ep:  48 train loss:  0.0603022 train acc:  0.9846250
ep:  49 train loss:  0.0601467 train acc:  0.9851250
ep:  50 train loss:  0.0586281 train acc:  0.9856250
ep:  51 train loss:  0.0590373 train acc:  0.9851250
ep:  52 train loss:  0.0596020 train acc:  0.9853750
ep:  53 train loss:  0.0592067 train acc:  0.9850000
ep:  54 train loss:  0.0587665 train acc:  0.9855000
ep:  55 train loss:  0.0579328 train acc:  0.9861250
ep:  56 train loss:  0.0569168 train acc:  0.9856250
ep:  57 train loss:  0.0572201 train acc:  0.9861250
ep:  58 train loss:  0.0578876 train acc:  0.9863750
ep:  59 train loss:  0.0561942 train acc:  0.9870000
ep:  60 train loss:  0.0567571 train acc:  0.9858750
ep:  61 train loss:  0.0572078 train acc:  0.9865000
ep:  62 train loss:  0.0561682 train acc:  0.9868750
ep:  63 train loss:  0.0556391 train acc:  0.9863750
ep:  64 train loss:  0.0555464 train acc:  0.9867500
ep:  65 train loss:  0.0591677 train acc:  0.9857500
ep:  66 train loss:  0.0557941 train acc:  0.9862500
ep:  67 train loss:  0.0545659 train acc:  0.9873750
ep:  68 train loss:  0.0565811 train acc:  0.9860000
ep:  69 train loss:  0.0549713 train acc:  0.9871250
ep:  70 train loss:  0.0529980 train acc:  0.9873750
ep:  71 train loss:  0.0550554 train acc:  0.9870000
ep:  72 train loss:  0.0540157 train acc:  0.9868750
ep:  73 train loss:  0.0534090 train acc:  0.9876250
ep:  74 train loss:  0.0543376 train acc:  0.9872500
ep:  75 train loss:  0.0540866 train acc:  0.9876250
ep:  76 train loss:  0.0567919 train acc:  0.9863750
ep:  77 train loss:  0.0536272 train acc:  0.9873750
ep:  78 train loss:  0.0524901 train acc:  0.9877500
ep:  79 train loss:  0.0534025 train acc:  0.9871250
ep:  80 train loss:  0.0524410 train acc:  0.9880000
ep:  81 train loss:  0.0556857 train acc:  0.9863750
ep:  82 train loss:  0.0548822 train acc:  0.9866250
ep:  83 train loss:  0.0525377 train acc:  0.9877500
ep:  84 train loss:  0.0520924 train acc:  0.9880000
ep:  85 train loss:  0.0516959 train acc:  0.9878750
ep:  86 train loss:  0.0532330 train acc:  0.9872500
ep:  87 train loss:  0.0539434 train acc:  0.9875000
ep:  88 train loss:  0.0517499 train acc:  0.9872500
ep:  89 train loss:  0.0513489 train acc:  0.9878750
ep:  90 train loss:  0.0516292 train acc:  0.9877500
ep:  91 train loss:  0.0546356 train acc:  0.9867500
ep:  92 train loss:  0.0527081 train acc:  0.9881250
ep:  93 train loss:  0.0512507 train acc:  0.9881250
ep:  94 train loss:  0.0513264 train acc:  0.9880000
ep:  95 train loss:  0.0511661 train acc:  0.9877500
ep:  96 train loss:  0.0527732 train acc:  0.9875000
ep:  97 train loss:  0.0512416 train acc:  0.9876250
ep:  98 train loss:  0.0508410 train acc:  0.9880000
ep:  99 train loss:  0.0510743 train acc:  0.9880000
ep:  100 train loss:  0.0514249 train acc:  0.9880000
ep:  101 train loss:  0.0510203 train acc:  0.9880000
ep:  102 train loss:  0.0509050 train acc:  0.9880000
ep:  103 train loss:  0.0522555 train acc:  0.9866250
ep:  104 train loss:  0.0517546 train acc:  0.9875000
ep:  105 train loss:  0.0502385 train acc:  0.9873750
ep:  106 train loss:  0.0499226 train acc:  0.9882500
ep:  107 train loss:  0.0515607 train acc:  0.9877500
ep:  108 train loss:  0.0500576 train acc:  0.9883750
ep:  109 train loss:  0.0505636 train acc:  0.9882500
ep:  110 train loss:  0.0508874 train acc:  0.9877500
ep:  111 train loss:  0.0498545 train acc:  0.9882500
ep:  112 train loss:  0.0495836 train acc:  0.9881250
ep:  113 train loss:  0.0553603 train acc:  0.9867500
ep:  114 train loss:  0.0507578 train acc:  0.9881250
ep:  115 train loss:  0.0494802 train acc:  0.9882500
ep:  116 train loss:  0.0492497 train acc:  0.9883750
ep:  117 train loss:  0.0494591 train acc:  0.9882500
ep:  118 train loss:  0.0493964 train acc:  0.9885000
ep:  119 train loss:  0.0498601 train acc:  0.9881250
ep:  120 train loss:  0.0493801 train acc:  0.9885000
ep:  121 train loss:  0.0498902 train acc:  0.9880000
ep:  122 train loss:  0.0499126 train acc:  0.9882500
ep:  123 train loss:  0.0486638 train acc:  0.9885000
ep:  124 train loss:  0.0529153 train acc:  0.9871250
ep:  125 train loss:  0.0508967 train acc:  0.9872500
ep:  126 train loss:  0.0493361 train acc:  0.9881250
ep:  127 train loss:  0.0484199 train acc:  0.9886250
ep:  128 train loss:  0.0481485 train acc:  0.9885000
ep:  129 train loss:  0.0514708 train acc:  0.9875000
ep:  130 train loss:  0.0493205 train acc:  0.9885000
ep:  131 train loss:  0.0484829 train acc:  0.9883750
ep:  132 train loss:  0.0484226 train acc:  0.9887500
ep:  133 train loss:  0.0486244 train acc:  0.9882500
ep:  134 train loss:  0.0485036 train acc:  0.9885000
ep:  135 train loss:  0.0511483 train acc:  0.9877500
ep:  136 train loss:  0.0495533 train acc:  0.9883750
ep:  137 train loss:  0.0481933 train acc:  0.9883750
ep:  138 train loss:  0.0479576 train acc:  0.9886250
ep:  139 train loss:  0.0553194 train acc:  0.9867500
ep:  140 train loss:  0.0488716 train acc:  0.9881250
ep:  141 train loss:  0.0482339 train acc:  0.9883750
ep:  142 train loss:  0.0477949 train acc:  0.9886250
ep:  143 train loss:  0.0477099 train acc:  0.9887500
ep:  144 train loss:  0.0477995 train acc:  0.9885000
ep:  145 train loss:  0.0488640 train acc:  0.9882500
ep:  146 train loss:  0.0489163 train acc:  0.9885000
ep:  147 train loss:  0.0479440 train acc:  0.9885000
ep:  148 train loss:  0.0481656 train acc:  0.9886250
ep:  149 train loss:  0.0479311 train acc:  0.9885000
ep:  150 train loss:  0.0499060 train acc:  0.9877500
ep:  151 train loss:  0.0488198 train acc:  0.9885000
ep:  152 train loss:  0.0480174 train acc:  0.9883750
ep:  153 train loss:  0.0484082 train acc:  0.9883750
ep:  154 train loss:  0.0474503 train acc:  0.9886250
ep:  155 train loss:  0.0477584 train acc:  0.9885000
ep:  156 train loss:  0.0504941 train acc:  0.9880000
ep:  157 train loss:  0.0483847 train acc:  0.9885000
ep:  158 train loss:  0.0477896 train acc:  0.9885000
ep:  159 train loss:  0.0480452 train acc:  0.9886250
ep:  160 train loss:  0.0477785 train acc:  0.9885000
ep:  161 train loss:  0.0498117 train acc:  0.9878750
ep:  162 train loss:  0.0487362 train acc:  0.9882500
ep:  163 train loss:  0.0476704 train acc:  0.9886250
ep:  164 train loss:  0.0474319 train acc:  0.9886250
ep:  165 train loss:  0.0476351 train acc:  0.9886250
ep:  166 train loss:  0.0481785 train acc:  0.9883750
ep:  167 train loss:  0.0476734 train acc:  0.9886250
ep:  168 train loss:  0.0476970 train acc:  0.9885000
ep:  169 train loss:  0.0475907 train acc:  0.9886250
ep:  170 train loss:  0.0477585 train acc:  0.9886250
ep:  171 train loss:  0.0499524 train acc:  0.9875000
ep:  172 train loss:  0.0478065 train acc:  0.9886250
ep:  173 train loss:  0.0471654 train acc:  0.9887500
ep:  174 train loss:  0.0477038 train acc:  0.9885000
ep:  175 train loss:  0.0470898 train acc:  0.9886250
ep:  176 train loss:  0.0518607 train acc:  0.9873750
ep:  177 train loss:  0.0475733 train acc:  0.9883750
ep:  178 train loss:  0.0472753 train acc:  0.9887500
ep:  179 train loss:  0.0468708 train acc:  0.9885000
ep:  180 train loss:  0.0472239 train acc:  0.9886250
ep:  181 train loss:  0.0470941 train acc:  0.9887500
ep:  182 train loss:  0.0492829 train acc:  0.9873750
ep:  183 train loss:  0.0501506 train acc:  0.9882500
ep:  184 train loss:  0.0472985 train acc:  0.9886250
ep:  185 train loss:  0.0469146 train acc:  0.9885000
ep:  186 train loss:  0.0472332 train acc:  0.9887500
ep:  187 train loss:  0.0470570 train acc:  0.9887500
ep:  188 train loss:  0.0473043 train acc:  0.9886250
ep:  189 train loss:  0.0474154 train acc:  0.9887500
ep:  190 train loss:  0.0473431 train acc:  0.9886250
ep:  191 train loss:  0.0473802 train acc:  0.9888750
ep:  192 train loss:  0.0472124 train acc:  0.9890000
ep:  193 train loss:  0.0471383 train acc:  0.9885000
ep:  194 train loss:  0.0498946 train acc:  0.9877500
ep:  195 train loss:  0.0474726 train acc:  0.9888750
ep:  196 train loss:  0.0468531 train acc:  0.9887500
ep:  197 train loss:  0.0471465 train acc:  0.9888750
ep:  198 train loss:  0.0471345 train acc:  0.9887500
ep:  199 train loss:  0.0526556 train acc:  0.9877500
