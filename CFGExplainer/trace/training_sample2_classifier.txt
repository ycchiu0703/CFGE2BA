2023-04-13 18:04:46.538745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-04-13 18:04:47.310247: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-13 18:04:47.310751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-04-13 18:04:47.373037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-04-13 18:04:47.373124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3080 Ti computeCapability: 8.6
coreClock: 1.83GHz coreCount: 80 deviceMemorySize: 11.75GiB deviceMemoryBandwidth: 849.46GiB/s
2023-04-13 18:04:47.373137: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-04-13 18:04:47.374531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-04-13 18:04:47.374587: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-04-13 18:04:47.375217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-13 18:04:47.375387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-13 18:04:47.376748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-13 18:04:47.377077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-04-13 18:04:47.377158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-04-13 18:04:47.377230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-04-13 18:04:47.377328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-04-13 18:04:47.377366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-04-13 18:08:23.401259: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-13 18:08:23.401460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-04-13 18:08:23.401560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3080 Ti computeCapability: 8.6
coreClock: 1.83GHz coreCount: 80 deviceMemorySize: 11.75GiB deviceMemoryBandwidth: 849.46GiB/s
2023-04-13 18:08:23.401588: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-04-13 18:08:23.401609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-04-13 18:08:23.401614: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-04-13 18:08:23.401619: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-13 18:08:23.401624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-13 18:08:23.401629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-13 18:08:23.401640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-04-13 18:08:23.401645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-04-13 18:08:23.401677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-04-13 18:08:23.401726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-04-13 18:08:23.401760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-04-13 18:08:23.401772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-04-13 18:08:23.643846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-04-13 18:08:23.643885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2023-04-13 18:08:23.643890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2023-04-13 18:08:23.644078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-04-13 18:08:23.644201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-04-13 18:08:23.644250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-04-13 18:08:23.644304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10873 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6)
2023-04-13 18:08:23.646154: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 7046430720 exceeds 10% of free system memory.
2023-04-13 18:12:15.946308: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 6710886400 exceeds 10% of free system memory.
2023-04-13 18:12:29.841001: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 7046430720 exceeds 10% of free system memory.
2023-04-13 18:12:33.128401: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-04-13 18:12:33.357252: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-04-13 18:12:33.380114: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-04-13 18:12:36.672141: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 6710886400 exceeds 10% of free system memory.
2023-04-13 18:12:42.912146: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 7046430720 exceeds 10% of free system memory.
sys.args:  ['exp_train_GCNClassifier.py', '10', 'data', '1024-512-128', '0.0001', 'GCNClassifier', '5%_Poison_connlabcfg', '50']
+ loaded padded_train Benign
+ loaded padded_train Malware
+ loaded train dataset
+ loaded padded_test Benign
+ loaded padded_test Malware
+ loaded test dataset
created Graph GCN model
+ model: 
 <util.models.GCN object at 0x7f023e5997f0>
ep:  0 train loss:  4.9152207 train acc:  0.4095238
ep:  1 train loss:  0.7861874 train acc:  0.5714286
ep:  2 train loss:  0.5863184 train acc:  0.8285714
ep:  3 train loss:  0.5401598 train acc:  0.8380952
ep:  4 train loss:  0.5059347 train acc:  0.8476191
ep:  5 train loss:  0.5020919 train acc:  0.8476191
ep:  6 train loss:  0.4683392 train acc:  0.8952381
ep:  7 train loss:  0.4527231 train acc:  0.8952381
ep:  8 train loss:  0.4454047 train acc:  0.9047619
ep:  9 train loss:  0.4272710 train acc:  0.9047619
ep:  10 train loss:  0.4026263 train acc:  0.9047619
ep:  11 train loss:  0.3838432 train acc:  0.9142857
ep:  12 train loss:  0.3672561 train acc:  0.9238095
ep:  13 train loss:  0.3528622 train acc:  0.9238095
ep:  14 train loss:  0.3342007 train acc:  0.9238095
ep:  15 train loss:  0.3102683 train acc:  0.9428571
ep:  16 train loss:  0.2932070 train acc:  0.9428571
ep:  17 train loss:  0.2736225 train acc:  0.9428571
ep:  18 train loss:  0.2585583 train acc:  0.9428571
ep:  19 train loss:  0.2439576 train acc:  0.9428571
ep:  20 train loss:  0.2368356 train acc:  0.9428571
ep:  21 train loss:  0.2109406 train acc:  0.9523810
ep:  22 train loss:  0.2057796 train acc:  0.9523810
ep:  23 train loss:  0.1805151 train acc:  0.9523810
ep:  24 train loss:  0.1790015 train acc:  0.9523810
ep:  25 train loss:  0.1553459 train acc:  0.9523810
ep:  26 train loss:  0.1640188 train acc:  0.9619048
ep:  27 train loss:  0.1358119 train acc:  0.9619048
ep:  28 train loss:  0.1279649 train acc:  0.9619048
ep:  29 train loss:  0.1195585 train acc:  0.9619048
ep:  30 train loss:  0.1113477 train acc:  0.9619048
ep:  31 train loss:  0.1158159 train acc:  0.9619048
ep:  32 train loss:  0.0965687 train acc:  0.9619048
ep:  33 train loss:  0.0894936 train acc:  0.9619048
ep:  34 train loss:  0.0827290 train acc:  0.9619048
ep:  35 train loss:  0.0763615 train acc:  0.9619048
ep:  36 train loss:  0.0706446 train acc:  0.9809524
ep:  37 train loss:  0.0644802 train acc:  0.9809524
ep:  38 train loss:  0.0600593 train acc:  0.9809524
ep:  39 train loss:  0.0584819 train acc:  0.9809524
ep:  40 train loss:  0.0527744 train acc:  0.9809524
ep:  41 train loss:  0.0503791 train acc:  0.9809524
ep:  42 train loss:  0.0483438 train acc:  0.9809524
ep:  43 train loss:  0.0467919 train acc:  0.9809524
ep:  44 train loss:  0.0452783 train acc:  0.9809524
ep:  45 train loss:  0.0441298 train acc:  0.9809524
ep:  46 train loss:  0.0428981 train acc:  0.9809524
ep:  47 train loss:  0.0423269 train acc:  0.9809524
ep:  48 train loss:  0.0567128 train acc:  0.9809524
ep:  49 train loss:  0.0400303 train acc:  0.9809524
